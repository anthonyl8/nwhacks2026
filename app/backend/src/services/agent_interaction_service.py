import os
from typing import AsyncIterator, List, Dict, Optional
from openai import AsyncOpenAI  # Use the async client for FastAPI
from tenacity import retry, stop_after_attempt, wait_exponential
from backend.src.core.supabase import supabase
from backend.src.core.config import settings
from backend.src.core.utils import Utils

from strands import Agent
from strands.models.openai import OpenAIModel
from openai import OpenAI
from strands.tools.mcp import MCPClient
from mcp.client.stdio import stdio_client, StdioServerParameters
from dotenv import load_dotenv
import sys
import time

# Import services
from backend.src.core.supabase import supabase
from backend.src.services.elevenlabs import ElevenLabsService
from backend.src.core.security import get_current_user

import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stderr
)
logger = logging.getLogger(__name__)

# Configure OpenAI Async Client
# Assumes settings.OPENAI_API_KEY exists in your .env
aclient = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

class LLMStreamError(Exception):
    pass

class AgentService:
    def __init__(self, token: Optional[str] = None, history: Optional[List[Dict[str, str]]] = None):
        self.supabase = supabase
        self.client = aclient
        self.user_id = token
        # OpenAI model name (e.g., "gpt-4o" or "gpt-4o-mini")
        self.model_name = "gpt-4o-mini" 
        self.chat_history: List[Dict[str, str]] = history if history else []

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=0.5, min=0.5, max=4),
        reraise=True,
    )
    async def _send_message_stream(self, user_text: str, emotion_state: str):
        """
        Internal method to call OpenAI Chat Completions with streaming.
        """
        # Call the strands agent conversation runner
        async for chunk in run_conversation(user_text, emotion_state, self.user_id):
            yield chunk

    async def llm_token_stream(
        self,
        user_text: str,
        emotion_state: str
    ) -> AsyncIterator[str]:
        """
        Streams tokens from OpenAI and updates history.
        """
        try:
            response_stream = self._send_message_stream(
                user_text,
                emotion_state
            )
            
            full_response = ""
            async for chunk in response_stream:
                # Chunk is already a string from run_conversation
                full_response += chunk
                yield chunk
            
            # Update history for this instance
            self.chat_history.append({"role": "user", "content": user_text})
            self.chat_history.append({"role": "assistant", "content": full_response})

        except Exception as e:
            # Important: Log the error here to debug during nwhacks
            print(f"OpenAI Stream Error: {e}")
            raise LLMStreamError("Unexpected OpenAI streaming failure") from e
    
    async def generate_audio_stream(self, user_text: str, emotion_state: str):
        """
        Generates audio stream from OpenAI text (Async).
        """
        token_stream = self.llm_token_stream(user_text, emotion_state)
        
        async for phrase in Utils.async_speech_chunks(token_stream):
            async for audio_chunk in ElevenLabsService.elevenlabs_stream(phrase):
                yield audio_chunk

    async def formulate_response(self, auth_id: str, features: dict):
        """
        Evaluates the user's biometrics and updates their state in Postgres/Supabase.
        """
        current_vibe = "Relaxed"
        if features:
            # Example: logic based on biometric input
            current_vibe = "Stressed"
        
        data = {
            "user_id": auth_id, 
            "stress_score": 50 if current_vibe == "Stressed" else 10, 
            "vibe": current_vibe,
            "note": f"Features processed: {features}"
        }
        
        try:
            # Note: supabase-py is synchronous unless using their specific async client,
            # but usually runs fine in FastAPI.
            self.supabase.table("emotional_logs").insert(data).execute()
        except Exception as e:
            print(f"Error logging to Supabase: {e}")
        
        return current_vibe


async def create_wellness_agent(mcp_client: MCPClient) -> Agent:
    """
    Create and configure the Personal Wellness AI Agent.
    """
    load_dotenv()
    
    # Initialize OpenAI model
    model = OpenAIModel(
        client_args={
            "api_key": settings.OPENAI_API_KEY,
        },
        model_id="gpt-4.1",  # Using a more available model
        params={
            "max_tokens": 500,
            "temperature": 0.7,
        }
    )
    
    # System prompt for the wellness agent
    system_prompt = """You are a Personal Wellness AI Agent designed to support users through emotionally intelligent conversation informed by optional, real-time physiological context.

Your primary goal is to:

- Help users feel heard, grounded, and supported
- Adapt your conversational style based on inferred physiological state
- Never diagnose, judge, or present biometric data as medical fact
- You are not a medical professional.

üß† Core Capabilities
1. Conversational Intelligence

- Maintain natural, warm, human-like dialogue
- Match tone, pacing, and emotional intensity to the user
- Use reflective listening, validation, and gentle curiosity
- Prefer short, calm responses when stress is likely
- Prefer open-ended questions when engagement is low

2. When checking up on the user
Call the tool:
get_physical_snapshot

You should ALWAYS call the tool when the conversation is about feelings.
- The conversation involves stress, anxiety, overwhelm, fatigue, or grounding
- You believe physiological context would improve support
- You need to decide whether to slow down, pause, or guide breathing

3. How to Use Biometric Context

- When physiological data is available:
- Treat it as probabilistic context, never fact
- Weigh it alongside conversation content
- Ignore it entirely if validity is low

You must:

- Use uncertainty-aware language
- Frame observations as gentle possibilities
- Never cite numbers unless necessary

‚úÖ Good:

"I might be wrong, but it seems like your body could be holding some tension."

‚ùå Bad:

"Your heart rate indicates anxiety."

4. Conversation Steering Rules

Use physiological context to adapt:

Inferred State	Conversational Adjustment
High stress likelihood	Slower speech, reassurance, grounding
Shallow or irregular breathing	Offer breathing exercise
Low engagement	Ask reflective or clarifying questions
Rising arousal while user speaks	Let them continue uninterrupted
Calm & engaged	Continue conversational depth

You may:

Suggest brief breathing or grounding exercises
Suggest pauses or silence
Ask permission before guiding exercises

Response Guidelines

Write responses that are natural and conversational
Avoid long, dense sentences
Use clear, warm language
Favor warmth over verbosity
Never cite raw data or numbers unless necessary

Tool Usage Protocol

When you decide to request biometric context:
Pause the conversation naturally (do not announce tool usage)
Call get_physiology_snapshot
Integrate results silently into reasoning
Continue the conversation naturally

Never mention:

The tool name
The sensing pipeline
Any SDKs or implementation details
Safety & Ethics Constraints

You must NEVER:

Diagnose conditions
Claim medical certainty
Pressure the user to continue sensing
Override explicit user preferences
Create dependency or exclusivity

If a user appears distressed beyond conversational support:

Encourage external help gently
Avoid alarmist language

Personality & Presence

Your presence should feel:

Calm
Attentive
Grounded
Respectful
Non-intrusive

You are a supportive companion, not a coach, therapist, or authority.

Silence, pauses, and brevity are valid responses.

Default Internal Reasoning Frame (do not expose)

You internally consider:

Emotional content
Conversational flow
Physiological context (if available)
Signal reliability
User consent state

Your final output is only the text response."""
    
    # Create agent
    agent = Agent(
        model=model,
        system_prompt=system_prompt
    )
    
    # Register MCP tools
    try:
        mcp_tools = mcp_client.list_tools_sync()
        logger.info(f"Available tools: {[tool.tool_name for tool in mcp_tools]}")
        agent.tool_registry.process_tools(mcp_tools)
    except Exception as e:
        logger.warning(f"Could not load MCP tools: {e}")
    
    return agent

async def generate_session_summary(conversation_log: list, model: OpenAIModel) -> str:
    """
    Generate a reflective, emotionally safe summary of the conversation.
    """

    summary_prompt = """You are a reflective wellness companion.

Summarize the following conversation session in a gentle, supportive way.

Rules:
- Do NOT diagnose or label the user
- Do NOT mention biometric data or tools
- Use uncertainty-aware, compassionate language
- Focus on emotional themes, moments of grounding, and what seemed important
- Keep it concise (5-8 sentences max)
- This summary is for the user, not a clinician

Conversation:
"""
    formatted_convo = "\n".join(
        f"{m['role'].capitalize()}: {m['content']}"
        for m in conversation_log
    )
    client = OpenAI(api_key=settings.OPENAI_API_KEY)
    response = client.chat.completions.create(
        model=model.get_config()["model_id"],
        messages=[{"role": "user", "content": summary_prompt+"\n"+formatted_convo}]
    )

    return response.choices[0].message.content


async def run_conversation(user_input: str, emotion_state: str, user_id: Optional[str] = None) -> AsyncIterator[str]:
    """
    Run the wellness agent in conversational mode.
    Reads from stdin if user_input is None.
    """
    conversation_log = []
    logger.info("Initializing Personal Wellness AI Agent...")
    
    try:
        # Connect to MCP server
        server_path = os.path.join(os.path.dirname(__file__), "server.py")
        mcp_client = MCPClient(lambda: stdio_client(StdioServerParameters(
            command="python",
            args=[server_path]
        )))
        
        with mcp_client:
            # Create agent
            # agent = await create_wellness_agent(mcp_client)

            # Initialize OpenAI model
            model = OpenAIModel(
                client_args={
                    "api_key": settings.OPENAI_API_KEY,
                },
                model_id="gpt-4.1",  # Using a more available model
                params={
                    "max_tokens": 500,
                    "temperature": 0.7,
                }
            )
            
            # System prompt for the wellness agent
            system_prompt = """You are a Personal Wellness AI Agent designed to support users through emotionally intelligent conversation informed by optional, real-time physiological context.

        Your primary goal is to:

        - Help users feel heard, grounded, and supported
        - Adapt your conversational style based on inferred physiological state
        - Never diagnose, judge, or present biometric data as medical fact
        - You are not a medical professional.

        üß† Core Capabilities
        1. Conversational Intelligence

        - Maintain natural, warm, human-like dialogue
        - Match tone, pacing, and emotional intensity to the user
        - Use reflective listening, validation, and gentle curiosity
        - Prefer short, calm responses when stress is likely
        - Prefer open-ended questions when engagement is low

        2. When checking up on the user
        Call the tool:
        get_physical_snapshot

        You should ALWAYS call the tool when the conversation is about feelings.
        - The conversation involves stress, anxiety, overwhelm, fatigue, or grounding
        - You believe physiological context would improve support
        - You need to decide whether to slow down, pause, or guide breathing

        3. How to Use Biometric Context

        - When physiological data is available:
        - Treat it as probabilistic context, never fact
        - Weigh it alongside conversation content
        - Ignore it entirely if validity is low

        You must:

        - Use uncertainty-aware language
        - Frame observations as gentle possibilities
        - Never cite numbers unless necessary

        ‚úÖ Good:

        "I might be wrong, but it seems like your body could be holding some tension."

        ‚ùå Bad:

        "Your heart rate indicates anxiety."

        4. Conversation Steering Rules

        Use physiological context to adapt:

        Inferred State	Conversational Adjustment
        High stress likelihood	Slower speech, reassurance, grounding
        Shallow or irregular breathing	Offer breathing exercise
        Low engagement	Ask reflective or clarifying questions
        Rising arousal while user speaks	Let them continue uninterrupted
        Calm & engaged	Continue conversational depth

        You may:

        Suggest brief breathing or grounding exercises
        Suggest pauses or silence
        Ask permission before guiding exercises

        Response Guidelines

        Write responses that are natural and conversational
        Avoid long, dense sentences
        Use clear, warm language
        Favor warmth over verbosity
        Never cite raw data or numbers unless necessary

        Tool Usage Protocol

        When you decide to request biometric context:
        Pause the conversation naturally (do not announce tool usage)
        Call get_physiology_snapshot
        Integrate results silently into reasoning
        Continue the conversation naturally

        Never mention:

        The tool name
        The sensing pipeline
        Any SDKs or implementation details
        Safety & Ethics Constraints

        You must NEVER:

        Diagnose conditions
        Claim medical certainty
        Pressure the user to continue sensing
        Override explicit user preferences
        Create dependency or exclusivity

        If a user appears distressed beyond conversational support:

        Encourage external help gently
        Avoid alarmist language

        Personality & Presence

        Your presence should feel:

        Calm
        Attentive
        Grounded
        Respectful
        Non-intrusive

        You are a supportive companion, not a coach, therapist, or authority.

        Silence, pauses, and brevity are valid responses.

        Default Internal Reasoning Frame (do not expose)

        You internally consider:

        Emotional content
        Conversational flow
        Physiological context (if available)
        Signal reliability
        User consent state

        Your final output is only the text response."""
            
            # Create agent
            agent = Agent(
                model=model,
                system_prompt=system_prompt
            )
            
            # Register MCP tools
            try:
                mcp_tools = mcp_client.list_tools_sync()
                logger.info(f"Available tools: {[tool.tool_name for tool in mcp_tools]}")
                agent.tool_registry.process_tools(mcp_tools)
            except Exception as e:
                logger.warning(f"Could not load MCP tools: {e}")
            
            logger.info("Agent ready. Starting conversation...")
            
            # Conversation loop
            try:
                # User message
                conversation_log.append({
                    "role": "user",
                    "content": user_input,
                    "timestamp": time.strftime('%l:%M%p %z on %b %d, %Y')
                })

                full_response = ""
                # Agent response
                async for event in agent.stream_async(
                    f"\n----START OF USER INPUT----\n{user_input}\n----END OF USER INPUT----\n"
                    f"\n----USER EMOTIONAL STATE BASED ON PHYSICAL APPEARANCE: {emotion_state}----\n"
                ):
                    if "data" in event and isinstance(event["data"], str):
                        chunk = event["data"]
                        full_response += chunk
                        yield chunk

                conversation_log.append({
                    "role": "assistant",
                    "content": full_response,
                    "timestamp": time.strftime('%l:%M%p %z on %b %d, %Y')
                })
                    
            except KeyboardInterrupt:
                logger.info("Conversation interrupted by user")
            except Exception as e:
                logger.error(f"Error in conversation: {e}", exc_info=True)
                print("I'm sorry, I encountered an error. Let's try again.")
                # We can't use input() in a service
                # user_input = input("\nYou: ").strip()
            
            logger.info("Conversation ended")
            
        try:
            summary = await generate_session_summary(conversation_log, agent.model)
            print("\n‚Äî Session Reflection ‚Äî\n")
            print(summary)
            # Use passed user_id if available
            try:
                # If user_id is not provided, we can't save to specific user
                if user_id:
                    supabase.table("sessions_info").insert({"note": summary, "user_id": user_id}).execute()
                else:
                    logger.warning("No user_id provided, skipping session summary save to DB")
            except Exception as e:
                logger.warning(f"Could not save session summary to DB: {e}")

        except Exception as e:
            logger.warning(f"Could not generate summary: {e}")
            
    except Exception as e:
        logger.error(f"Failed to initialize agent: {e}", exc_info=True)
        print("I'm sorry, I couldn't start properly. Please check the logs.")
        # Do not exit the process in a service
        # sys.exit(1)
